{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83c0992",
   "metadata": {},
   "source": [
    "### Incorporations (Embeddings)\n",
    "\n",
    "Les incorporations sont une méthode pour représenter des mots ou des tokens sous forme de vecteurs numériques dans un espace vectoriel. Ces vecteurs sont appris à partir des données d'entraînement du modèle. \n",
    "\n",
    "Supposons que nous ayons un vocabulaire de taille $V$ (c'est-à-dire, $V$ mots différents). Chaque mot est représenté par un vecteur de dimension $d$ (où $d$ est la dimension de l'incorporation). Ces vecteurs de mots sont organisés dans une matrice appelée matrice d'incorporation $E$ de taille $V \\times d$.\n",
    "\n",
    "Ainsi, si $w_i$ est le vecteur d'incorporation du mot $i$ (où $i$ est l'indice du mot dans le vocabulaire), alors $E[i]$ donne le vecteur d'incorporation du mot $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f38d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d83bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  torch.Size([1, 10])\n",
      "Output:  torch.Size([1, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "# Définir la longueur maximale de la séquence et la dimension d'intégration\n",
    "max_len = 10\n",
    "d_model = 32\n",
    "vocab_size = 100  # Taille du vocabulaire\n",
    "\n",
    "# Générer des données aléatoires (batch_size=1, sequence_length=max_len)\n",
    "random_data = torch.randint(0, vocab_size, (1, max_len))  # Random integers as token IDs\n",
    "\n",
    "# Définir la couche d'intégration\n",
    "embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "# Appliquer la couche d'intégration pour obtenir l'intégration des mots\n",
    "word_embeddings = embedding_layer(random_data)\n",
    "print('Input: ',random_data.shape)\n",
    "print('Output: ',word_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4fc3aa",
   "metadata": {},
   "source": [
    "L'équation de position utilisée dans les transformers NLP, comme l'architecture Transformer originale développée par Vaswani et al. (2017), est basée sur l'utilisation des fonctions sinus et cosinus. Cette équation est utilisée pour incorporer des informations de position dans les plongements d'entrée, permettant au modèle de distinguer entre différentes positions dans la séquence.\n",
    "\n",
    "Dans le modèle Transformer, les encodages de position sont ajoutés aux plongements d'entrée pour fournir des informations sur la position de chaque jeton dans la séquence. C'est crucial car contrairement aux réseaux neuronaux récurrents (RNN) ou aux réseaux neuronaux convolutifs (CNN), le Transformer traite l'ensemble de la séquence d'entrée en parallèle, ce qui signifie qu'il ne comprend pas intrinsèquement l'ordre ou la position des jetons dans une séquence.\n",
    "\n",
    "La position $p$ d'un jeton dans une séquence peut être représentée comme un vecteur $\\mathbf{p} \\in \\mathbb{R}^d$, où $d$ est la dimension de l'intégration. L'encodage de position $\\mathbf{PE}(p)$ est calculé comme suit :\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{PE}(p, 2i) &= \\sin\\left(\\frac{p}{10000^{2i/d}}\\right) \\\\\n",
    "\\text{PE}(p, 2i+1) &= \\cos\\left(\\frac{p}{10000^{2i/d}}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Ici, $p$ fait référence à la position du jeton dans la séquence, $i$ représente l'indice de dimension dans l'intégration, et $d$ est la dimension de l'intégration.\n",
    "\n",
    "Cette formule garantit que chaque dimension de l'encodage de position correspond à une fonction sinusoidale de longueur d'onde différente. Cela permet au modèle de généraliser sur différentes longueurs de séquence.\n",
    "\n",
    "Ces encodages de position sont ensuite ajoutés aux plongements d'entrée avant d'être introduits dans le modèle. De cette manière, le modèle reçoit des informations sur la position des jetons, ce qui lui permet de comprendre l'ordre dans lequel ils apparaissent dans la séquence d'entrée.\n",
    "\n",
    "En incorporant des informations de position à travers les fonctions sinus et cosinus, les transformers sont capables de traiter efficacement et de comprendre des séquences de longueurs variables, ce qui constitue un avantage clé de cette architecture dans les tâches de traitement du langage naturel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e57206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pos_Encoder(nn.Module):\n",
    "    def __init__(self,  max_len,d_model):\n",
    "        super(Pos_Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        for pos in range(max_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                \n",
    "                pe[pos, i] = math.sin(pos/(10000**((i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos/(10000**(((i))/d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input = batch_size X seq_len X d_model\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d19447ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des encastrements positionnels\n",
    "pos_encodings = Pos_Encoder(max_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cd0479d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Embedding:  torch.Size([1, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "# Ajouter des embeddings positionnels aux embeddings de mots\n",
    "final_embeddings =pos_encodings(word_embeddings)\n",
    "print('Final Embedding: ',final_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e9dbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe=pos_encodings.pe.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9b39ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22ebe29ef90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(pe[0],'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7c0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
